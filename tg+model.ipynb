{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hchgssarwyh/ai_fiction/blob/features/tg%2Bmodel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OrfXFSS0xrwn"
      },
      "source": [
        "# Telegram bot"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pyTelegramBotAPI"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Nq6hZQHQoyi",
        "outputId": "4c67f094-3592-453b-ec1d-24fec8f5c832"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyTelegramBotAPI\n",
            "  Downloading pyTelegramBotAPI-4.12.0.tar.gz (232 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.0/232.0 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from pyTelegramBotAPI) (2.27.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->pyTelegramBotAPI) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->pyTelegramBotAPI) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->pyTelegramBotAPI) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->pyTelegramBotAPI) (3.4)\n",
            "Building wheels for collected packages: pyTelegramBotAPI\n",
            "  Building wheel for pyTelegramBotAPI (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyTelegramBotAPI: filename=pyTelegramBotAPI-4.12.0-py3-none-any.whl size=213956 sha256=d420c13a5a18bd8b25e3b564a93094157f7b1060cc7f42f2a4734c8ed29040a5\n",
            "  Stored in directory: /root/.cache/pip/wheels/7e/ba/82/f3ab5bc48525778633bccc741c0424677ed3435736221819f4\n",
            "Successfully built pyTelegramBotAPI\n",
            "Installing collected packages: pyTelegramBotAPI\n",
            "Successfully installed pyTelegramBotAPI-4.12.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import pickle\n",
        "\n",
        "import telebot;\n",
        "from telebot import types\n",
        "\n"
      ],
      "metadata": {
        "id": "c8GbzKxDIEXN"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TextRNN(nn.Module):\n",
        "    \n",
        "    def __init__(self, input_size, hidden_size, embedding_size, n_layers=1):\n",
        "        super(TextRNN, self).__init__()\n",
        "        \n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.embedding_size = embedding_size\n",
        "        self.n_layers = n_layers\n",
        "\n",
        "        self.encoder = nn.Embedding(self.input_size, self.embedding_size)\n",
        "        self.lstm = nn.LSTM(self.embedding_size, self.hidden_size, self.n_layers)\n",
        "        self.dropout = nn.Dropout(0.2)\n",
        "        self.fc = nn.Linear(self.hidden_size, self.input_size)\n",
        "        \n",
        "    def forward(self, x, hidden):\n",
        "        x = self.encoder(x).squeeze(2)\n",
        "        out, (ht1, ct1) = self.lstm(x, hidden)\n",
        "        out = self.dropout(out)\n",
        "        x = self.fc(out)\n",
        "        return x, (ht1, ct1)\n",
        "    \n",
        "    def init_hidden(self, batch_size=1):\n",
        "        return (torch.zeros(self.n_layers, batch_size, self.hidden_size, requires_grad=True).to(device),\n",
        "               torch.zeros(self.n_layers, batch_size, self.hidden_size, requires_grad=True).to(device))"
      ],
      "metadata": {
        "id": "I5EIr1JXIEAL"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate1(model, char_to_idx, idx_to_char, start_text=' ', prediction_len=200, temp=0.3):\n",
        "    with open('idx_to_char_hokku.pickle', 'rb') as f:\n",
        "      idx_to_char = pickle.load(f)\n",
        "    with open('char_to_idx_hokku.pickle', 'rb') as f:\n",
        "      char_to_idx = pickle.load(f)\n",
        "    hidden = model.init_hidden()\n",
        "    idx_input = [char_to_idx[char] for char in start_text]\n",
        "    train = torch.LongTensor(idx_input).view(-1, 1, 1).to(device)\n",
        "    predicted_text = start_text\n",
        "    \n",
        "    _, hidden = model(train, hidden)\n",
        "        \n",
        "    inp = train[-1].view(-1, 1, 1)\n",
        "    \n",
        "    for i in range(prediction_len):\n",
        "        output, hidden = model(inp.to(device), hidden)\n",
        "        output_logits = output.cpu().data.view(-1)\n",
        "        p_next = F.softmax(output_logits / temp, dim=-1).detach().cpu().data.numpy()        \n",
        "        top_index = np.random.choice(len(char_to_idx), p=p_next)\n",
        "        inp = torch.LongTensor([top_index]).view(-1, 1, 1).to(device)\n",
        "        predicted_char = idx_to_char[top_index]\n",
        "        predicted_text += predicted_char\n",
        "    \n",
        "    return predicted_text"
      ],
      "metadata": {
        "id": "ubPqoTa0Igpg"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate2(model, char_to_idx, idx_to_char, start_text=' ', prediction_len=200, temp=0.3):\n",
        "    with open('idx_to_char_harms.pickle', 'rb') as f:\n",
        "      idx_to_char = pickle.load(f)\n",
        "    with open('char_to_idx_harms.pickle', 'rb') as f:\n",
        "      char_to_idx = pickle.load(f)\n",
        "    hidden = model.init_hidden()\n",
        "    idx_input = [char_to_idx[char] for char in start_text]\n",
        "    train = torch.LongTensor(idx_input).view(-1, 1, 1).to(device)\n",
        "    predicted_text = start_text\n",
        "    \n",
        "    _, hidden = model(train, hidden)\n",
        "        \n",
        "    inp = train[-1].view(-1, 1, 1)\n",
        "    \n",
        "    for i in range(prediction_len):\n",
        "        output, hidden = model(inp.to(device), hidden)\n",
        "        output_logits = output.cpu().data.view(-1)\n",
        "        p_next = F.softmax(output_logits / temp, dim=-1).detach().cpu().data.numpy()        \n",
        "        top_index = np.random.choice(len(char_to_idx), p=p_next)\n",
        "        inp = torch.LongTensor([top_index]).view(-1, 1, 1).to(device)\n",
        "        predicted_char = idx_to_char[top_index]\n",
        "        predicted_text += predicted_char\n",
        "    \n",
        "    return predicted_text"
      ],
      "metadata": {
        "id": "HDWQiIv3Kizo"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate3(model, char_to_idx, idx_to_char, start_text=' ', prediction_len=200, temp=0.3):\n",
        "    with open('idx_to_char_sesenin.pickle', 'rb') as f:\n",
        "      idx_to_char = pickle.load(f)\n",
        "    with open('char_to_idx_sesenin.pickle', 'rb') as f:\n",
        "      char_to_idx = pickle.load(f)\n",
        "    hidden = model.init_hidden()\n",
        "    idx_input = [char_to_idx[char] for char in start_text]\n",
        "    train = torch.LongTensor(idx_input).view(-1, 1, 1).to(device)\n",
        "    predicted_text = start_text\n",
        "    \n",
        "    _, hidden = model(train, hidden)\n",
        "        \n",
        "    inp = train[-1].view(-1, 1, 1)\n",
        "    \n",
        "    for i in range(prediction_len):\n",
        "        output, hidden = model(inp.to(device), hidden)\n",
        "        output_logits = output.cpu().data.view(-1)\n",
        "        p_next = F.softmax(output_logits / temp, dim=-1).detach().cpu().data.numpy()        \n",
        "        top_index = np.random.choice(len(char_to_idx), p=p_next)\n",
        "        inp = torch.LongTensor([top_index]).view(-1, 1, 1).to(device)\n",
        "        predicted_char = idx_to_char[top_index]\n",
        "        predicted_text += predicted_char\n",
        "    \n",
        "    return predicted_text"
      ],
      "metadata": {
        "id": "55utUkIJKmKL"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
      ],
      "metadata": {
        "id": "7_Kv_Pj8SSlS"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('idx_to_char_hokku.pickle', 'rb') as f:\n",
        "  idx_to_char_hokku = pickle.load(f)\n",
        "model_hokku = TextRNN(input_size=len(idx_to_char_hokku), hidden_size=128, embedding_size=128, n_layers=2)\n",
        "model_hokku.load_state_dict(torch.load('model_hokku',map_location=torch.device('cpu')))\n",
        "model_hokku.eval()"
      ],
      "metadata": {
        "id": "TAkMre1zIh9j",
        "outputId": "624f809e-3171-4a2d-a576-4732e86f0bf6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TextRNN(\n",
              "  (encoder): Embedding(70, 128)\n",
              "  (lstm): LSTM(128, 128, num_layers=2)\n",
              "  (dropout): Dropout(p=0.2, inplace=False)\n",
              "  (fc): Linear(in_features=128, out_features=70, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('idx_to_char_harms.pickle', 'rb') as f:\n",
        "  idx_to_char_harms = pickle.load(f)\n",
        "model_harms = TextRNN(input_size=len(idx_to_char_harms), hidden_size=128, embedding_size=128, n_layers=2)\n",
        "model_harms.load_state_dict(torch.load('model_harms',map_location=torch.device('cpu')))\n",
        "model_harms.eval()"
      ],
      "metadata": {
        "id": "bkB-SwEeIl-g",
        "outputId": "c7c0236a-9b48-4826-829f-36c3a48aeea0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TextRNN(\n",
              "  (encoder): Embedding(84, 128)\n",
              "  (lstm): LSTM(128, 128, num_layers=2)\n",
              "  (dropout): Dropout(p=0.2, inplace=False)\n",
              "  (fc): Linear(in_features=128, out_features=84, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('idx_to_char_sesenin.pickle', 'rb') as f:\n",
        "  idx_to_char_sesenin = pickle.load(f)\n",
        "model_sesenin = TextRNN(input_size=len(idx_to_char_sesenin), hidden_size=128, embedding_size=128, n_layers=2)\n",
        "model_sesenin.load_state_dict(torch.load('model_sesenin',map_location=torch.device('cpu')))\n",
        "model_sesenin.eval()"
      ],
      "metadata": {
        "id": "hFdAD_DbImv-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model_hokku.to(device)\n",
        "model_harms.to(device)\n",
        "model_sesenin.to(device)"
      ],
      "metadata": {
        "id": "JZRO3wRtJBtX",
        "outputId": "f850e0bb-e272-40f5-e1b4-61f85247e607",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TextRNN(\n",
              "  (encoder): Embedding(105, 128)\n",
              "  (lstm): LSTM(128, 128, num_layers=2)\n",
              "  (dropout): Dropout(p=0.2, inplace=False)\n",
              "  (fc): Linear(in_features=128, out_features=105, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def poem_hokku(start):\n",
        "  with open('idx_to_char_hokku.pickle', 'rb') as f:\n",
        "    idx_to_char_hokku = pickle.load(f)\n",
        "  with open('char_to_idx_hokku.pickle', 'rb') as f:\n",
        "    char_to_idx_hokku = pickle.load(f)\n",
        "  s = evaluate1(\n",
        "      model_hokku, \n",
        "      char_to_idx_hokku, \n",
        "      idx_to_char_hokku, \n",
        "      temp=0.3, \n",
        "      prediction_len=200, \n",
        "      start_text=str(start)+' '\n",
        "    )\n",
        "  return s"
      ],
      "metadata": {
        "id": "nC-3s5ZiJKGk"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def poem_harms(start):\n",
        "  with open('idx_to_char_harms.pickle', 'rb') as f:\n",
        "    idx_to_char_harms = pickle.load(f)\n",
        "  with open('char_to_idx_harms.pickle', 'rb') as f:\n",
        "    char_to_idx_harms = pickle.load(f)\n",
        "  print(evaluate2(\n",
        "      model_harms, \n",
        "      char_to_idx_harms, \n",
        "      idx_to_char_harms, \n",
        "      temp=0.3, \n",
        "      prediction_len=200, \n",
        "      start_text=str(start)+' '\n",
        "    )\n",
        ")"
      ],
      "metadata": {
        "id": "L-Czw-QlJq0F"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def poem_sesenin(start):\n",
        "  with open('idx_to_char_sesenin.pickle', 'rb') as f:\n",
        "    idx_to_char_sesenin = pickle.load(f)\n",
        "  with open('char_to_idx_sesenin.pickle', 'rb') as f:\n",
        "    char_to_idx_sesenin = pickle.load(f)\n",
        "  print(evaluate3(\n",
        "      model_sesenin, \n",
        "      char_to_idx_sesenin, \n",
        "      idx_to_char_sesenin, \n",
        "      temp=0.3, \n",
        "      prediction_len=200, \n",
        "      start_text=str(start)+' '\n",
        "    )\n",
        ")"
      ],
      "metadata": {
        "id": "sX6LoanhJ4lG"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bot = telebot.TeleBot('5912676709:AAFogJDypnO9nA9GZ9bKMB4Kw4ul_d7CYQk');\n",
        "word = '';\n",
        "\n",
        "@bot.message_handler(content_types=['text'])\n",
        "def get_first_messages(message):\n",
        "\n",
        "\n",
        "    if message.text == \"/help\":\n",
        "        bot.send_message(message.from_user.id, 'Список команд: \\n /author - выбор стиля для стиха или прозы \\n /poem - выбор первого слова для начала стиха')\n",
        "    elif message.text == \"/poem\":\n",
        "        bot.send_message(message.from_user.id, \"Введи первое слово\")\n",
        "        bot.register_next_step_handler(message, get_word);\n",
        "    \n",
        "    elif message.text == \"/author\":\n",
        "\n",
        "        keyboard_author = types.InlineKeyboardMarkup(); #наша клавиатура\n",
        "\n",
        "        key_hokku = types.InlineKeyboardButton(text='Хокку', callback_data='hokku');\n",
        "        keyboard_author.add(key_hokku); #добавляем кнопку c хокку\n",
        "        key_esenin= types.InlineKeyboardButton(text='Есенин', callback_data='esenin');\n",
        "        keyboard_author.add(key_esenin);#добавляем кнопку c Есенином\n",
        "        key_harms= types.InlineKeyboardButton(text='Хармс', callback_data='harms');\n",
        "        keyboard_author.add(key_harms);#добавляем кнопку c Хармсом\n",
        "\n",
        "        header = 'Список стилей';\n",
        "        bot.send_message(message.from_user.id, text=header, reply_markup=keyboard_author)\n",
        "\n",
        "    elif message.text == \"/start\":\n",
        "        bot.send_message(message.from_user.id,'Отправь /poem и я сочиню для тебя что то!' )\n",
        "    else:\n",
        "        bot.send_message(message.from_user.id, \"Я тебя не понимаю. Напиши /help.\")\n",
        "\n",
        "\n",
        "def get_word(message): #получаем слово\n",
        "    global word;\n",
        "    word = message.text;\n",
        "\n",
        "    bot.send_message(message.from_user.id, word + \" я люблю \\n И кушать кашу я люблю \\n Вот такой вот белый стих\")\n",
        "\n",
        "    keyboard_word = types.InlineKeyboardMarkup(); #наша клавиатура\n",
        "\n",
        "    key_yes = types.InlineKeyboardButton(text='Да', callback_data='yes'); #кнопка «Да»\n",
        "    keyboard_word.add(key_yes); #добавляем кнопку в клавиатуру\n",
        "    key_no= types.InlineKeyboardButton(text='Нет', callback_data='no');\n",
        "    keyboard_word.add(key_no);\n",
        "    question = 'Попробовать еще?';\n",
        "    bot.send_message(message.from_user.id, text=question, reply_markup=keyboard_word)\n",
        "\n",
        "    \n",
        "def get_word_hokku(message): #получаем слово\n",
        "    global word;\n",
        "    word = message.text;\n",
        "\n",
        "    bot.send_message(message.from_user.id, poem_hokku(word + \" \"))\n",
        "\n",
        "    keyboard_word = types.InlineKeyboardMarkup(); #наша клавиатура\n",
        "\n",
        "    key_yes = types.InlineKeyboardButton(text='Да', callback_data='yes'); #кнопка «Да»\n",
        "    keyboard_word.add(key_yes); #добавляем кнопку в клавиатуру\n",
        "    key_no= types.InlineKeyboardButton(text='Нет', callback_data='no');\n",
        "    keyboard_word.add(key_no);\n",
        "    question = 'Попробовать еще?';\n",
        "    bot.send_message(message.from_user.id, text=question, reply_markup=keyboard_word)\n",
        "\n",
        "def get_word_harms(message): #получаем слово\n",
        "    global word;\n",
        "    word = message.text;\n",
        "\n",
        "    bot.send_message(message.from_user.id, poem_harms(word + \" \"))\n",
        "\n",
        "    keyboard_word = types.InlineKeyboardMarkup(); #наша клавиатура\n",
        "\n",
        "    key_yes = types.InlineKeyboardButton(text='Да', callback_data='yes'); #кнопка «Да»\n",
        "    keyboard_word.add(key_yes); #добавляем кнопку в клавиатуру\n",
        "    key_no= types.InlineKeyboardButton(text='Нет', callback_data='no');\n",
        "    keyboard_word.add(key_no);\n",
        "    question = 'Попробовать еще?';\n",
        "    bot.send_message(message.from_user.id, text=question, reply_markup=keyboard_word)\n",
        "\n",
        "def get_word_sesenin(message): #получаем слово\n",
        "    global word;\n",
        "    word = message.text;\n",
        "\n",
        "    bot.send_message(message.from_user.id, poem_sesenin(word ))\n",
        "\n",
        "    keyboard_word = types.InlineKeyboardMarkup(); #наша клавиатура\n",
        "\n",
        "    key_yes = types.InlineKeyboardButton(text='Да', callback_data='yes'); #кнопка «Да»\n",
        "    keyboard_word.add(key_yes); #добавляем кнопку в клавиатуру\n",
        "    key_no= types.InlineKeyboardButton(text='Нет', callback_data='no');\n",
        "    keyboard_word.add(key_no);\n",
        "    question = 'Попробовать еще?';\n",
        "    bot.send_message(message.from_user.id, text=question, reply_markup=keyboard_word)\n",
        "\n",
        "@bot.callback_query_handler(func=lambda call: call.data == \"yes\" or call.data == 'no')\n",
        "\n",
        "def callback_worker(call):\n",
        "    if call.data == \"yes\": #call.data это callback_data, которую мы указали при объявлении кнопки\n",
        "        bot.send_message(call.message.chat.id, 'Введи первое слово');\n",
        "        bot.register_next_step_handler(call.message, get_word);\n",
        "    elif call.data == \"no\":\n",
        "        bot.send_message(call.message.chat.id, ':(');\n",
        "\n",
        "@bot.callback_query_handler(func=lambda call: call.data == \"hokku\" or call.data == 'esenin' or call.data == 'harms')\n",
        "def callback_author(call):\n",
        "    if call.data == \"hokku\": \n",
        "        bot.send_message(call.message.chat.id, 'Введи первое слово');\n",
        "\n",
        "        bot.register_next_step_handler(call.message, get_word_hokku);\n",
        "    elif call.data == \"esenin\":\n",
        "        bot.send_message(call.message.chat.id, 'Введи первое слово');\n",
        "        bot.register_next_step_handler(call.message, get_word_sesenin);\n",
        "    elif call.data == \"harms\":\n",
        "        bot.send_message(call.message.chat.id, 'Введи первое слово');\n",
        "        bot.register_next_step_handler(call.message, get_word_harms);\n",
        "\n"
      ],
      "metadata": {
        "id": "h8c5ySBcTOhI"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bot.polling(none_stop=True, interval=0) "
      ],
      "metadata": {
        "id": "iJ9vI5LQTREH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#poem_harms('всем привет')"
      ],
      "metadata": {
        "id": "yfj1ZClOKEnw",
        "outputId": "4f65fcd9-2120-40f2-e45d-d12dcc922f79",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "всем привет   и нас\n",
            " Прозвонить бульдог,\n",
            " а по дороге,\n",
            " по панели,\n",
            " бегал Мишка\n",
            " по панели\n",
            " и кричал он:\n",
            " «Жу-жу-жу!\n",
            " Я теперь уже не Мишка,\n",
            " я совой пор делившись показ\n",
            "     потом начинается голод,\n",
            " Воздух с крю\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}